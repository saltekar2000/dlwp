{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify movie reviews in the IMDB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "imdb = tf.keras.datasets.imdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset of reviews and their labels\n",
    "# limit review text to top 10000 commonly occuring words\n",
    "imdb = tf.keras.datasets.imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = 10000)\n",
    "min_index = min([min(s) for s in train_data])\n",
    "max_index = max([max(s) for s in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary of train_data\n",
      "---------------------\n",
      "type: <class 'numpy.ndarray'>\n",
      "shape: (25000,)\n",
      "type of train_data[0]: <class 'list'>\n",
      "length of train_data[:5]: [218, 189, 141, 550, 147]\n",
      "type of train_data[0][0]: <class 'int'>\n",
      "train_data[0][:10]: [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]\n",
      "minimum entry in train_data: 1\n",
      "maximum entry in train_data: 9999\n",
      "\n",
      "summary of train_labels\n",
      "-----------------------\n",
      "type: <class 'numpy.ndarray'>\n",
      "shape: (25000,)\n",
      "type of train_labels[0]: <class 'numpy.int64'>\n",
      "train_labels[:10]: [1 0 0 1 0 0 1 0 1 0]\n",
      "number of negative reviews: 12500\n",
      "number of positive reviews: 12500\n",
      "\n",
      "summary of test_data\n",
      "--------------------\n",
      "shape: (25000,)\n",
      "\n",
      "summary of test_labels\n",
      "----------------------\n",
      "shape: (25000,)\n",
      "number of negative reviews: 12500\n",
      "number of positive reviews: 12500\n"
     ]
    }
   ],
   "source": [
    "print('summary of train_data')\n",
    "print('---------------------')\n",
    "print('type: ' + str(type(train_data)))\n",
    "print('shape: ' + str(train_data.shape))\n",
    "print('type of train_data[0]: ' + str(type(train_data[0])))\n",
    "print('length of train_data[:5]: ' + str([len(train_data[i]) for i in range(5)]))\n",
    "print('type of train_data[0][0]: ' + str(type(train_data[0][0])))\n",
    "print('train_data[0][:10]: ' + str(train_data[0][:10]))\n",
    "print('minimum entry in train_data: ' + str(min_index))\n",
    "print('maximum entry in train_data: ' + str(max_index))\n",
    "print()\n",
    "print('summary of train_labels')\n",
    "print('-----------------------')\n",
    "print('type: ' + str(type(train_labels)))\n",
    "print('shape: ' + str(train_labels.shape))\n",
    "print('type of train_labels[0]: ' + str(type(train_labels[0])))\n",
    "print('train_labels[:10]: ' + str(train_labels[:10]))\n",
    "print('number of negative reviews: ' + str(np.sum(train_labels == 0)))\n",
    "print('number of positive reviews: ' + str(np.sum(train_labels == 1)))\n",
    "print()\n",
    "print('summary of test_data')\n",
    "print('--------------------')\n",
    "print('shape: ' + str(test_data.shape))\n",
    "print()\n",
    "print('summary of test_labels')\n",
    "print('----------------------')\n",
    "print('shape: ' + str(test_labels.shape))\n",
    "print('number of negative reviews: ' + str(np.sum(test_labels == 0)))\n",
    "print('number of positive reviews: ' + str(np.sum(test_labels == 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word to index mapping and create reverse mapping from index to word\n",
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = { value:key for key,value in word_index.items() }\n",
    "\n",
    "# helper function to decode index encoded reviews\n",
    "def decode_review( encoded_review ) : \n",
    "    return ' '.join([reverse_word_index.get(i-3, '?') for i in encoded_review])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "number of entries word to index mapping dictionary: 88584\n",
      "number of entries index to word mapping dictionary: 88584\n",
      "low index values are common words: ['the', 'and', 'a', 'of', 'to', 'is', 'br', 'in', 'it']\n",
      "\n",
      "example of a positive review:\n",
      "-----------------------------\n",
      "? lavish production values and solid performances in this straightforward adaption of jane ? satirical classic about the marriage game within and between the classes in ? 18th century england northam and paltrow are a ? mixture as friends who must pass through ? and lies to discover that they love each other good humor is a ? virtue which goes a long way towards explaining the ? of the aged source material which has been toned down a bit in its harsh ? i liked the look of the film and how shots were set up and i thought it didn't rely too much on ? of head shots like most other films of the 80s and 90s do very good results\n",
      "\n",
      "example of a negative review:\n",
      "-----------------------------\n",
      "? this has to be one of the worst films of the 1990s when my friends i were watching this film being the target audience it was aimed at we just sat watched the first half an hour with our jaws touching the floor at how bad it really was the rest of the time everyone else in the theatre just started talking to each other leaving or generally crying into their popcorn that they actually paid money they had ? working to watch this feeble excuse for a film it must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can't get across how ? this is to watch save yourself an hour a bit of your life\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print('number of entries word to index mapping dictionary: ' + str(len(word_index)))\n",
    "print('number of entries index to word mapping dictionary: ' + str(len(reverse_word_index)))\n",
    "print('low index values are common words: ' + str([reverse_word_index[i] for i in range(1,10)]))\n",
    "print()\n",
    "print('example of a positive review:')\n",
    "print('-----------------------------')\n",
    "positive_index = 6\n",
    "print(decode_review(train_data[positive_index]))\n",
    "print()\n",
    "print('example of a negative review:')\n",
    "print('-----------------------------')\n",
    "negative_index = 2\n",
    "print(decode_review(train_data[negative_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a histogram of frequency counts of each index\n",
    "import itertools\n",
    "flatlist = list(itertools.chain.from_iterable(train_data))  # concatinate reviews\n",
    "freq = np.bincount(flatlist)/len(flatlist)  # count occurance of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of bigrams from flat list\n",
    "bigramlist = list(zip(flatlist[:-1],flatlist[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary encoding of reviews\n",
    "def vectorize_sequences( sequences, dimension = 10000 ):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i,sequence] = 1\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize labels -- don't know why this is necessary (int64-->float32?)\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tf.keras.models\n",
    "layers = tf.keras.layers\n",
    "\n",
    "def build_model1():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
